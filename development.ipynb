{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ariel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Library imports\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import sys\n",
    "import zarr\n",
    "import json\n",
    "import os\n",
    "import napari\n",
    "from rich import print as rprint  # Import rich's print function\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "from monai.transforms import Compose, RandFlipd, RandRotated, RandGaussianNoised, RandAdjustContrastd\n",
    "# set torch and cuda seed for reproducibility\n",
    "torch.manual_seed(37)\n",
    "torch.cuda.manual_seed(37)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomogram shape for TS_5_4 (z, y, x): (184, 630, 630)\n",
      "Loaded 11 points for virus-like-particle in TS_5_4.\n",
      "Loaded 46 points for apo-ferritin in TS_5_4.\n",
      "Loaded 10 points for beta-amylase in TS_5_4.\n",
      "Loaded 12 points for beta-galactosidase in TS_5_4.\n",
      "Loaded 31 points for ribosome in TS_5_4.\n",
      "Loaded 30 points for thyroglobulin in TS_5_4.\n",
      "Tomogram shape for TS_69_2 (z, y, x): (184, 630, 630)\n",
      "Loaded 9 points for virus-like-particle in TS_69_2.\n",
      "Loaded 35 points for apo-ferritin in TS_69_2.\n",
      "Loaded 12 points for beta-amylase in TS_69_2.\n",
      "Loaded 16 points for beta-galactosidase in TS_69_2.\n",
      "Loaded 37 points for ribosome in TS_69_2.\n",
      "Loaded 34 points for thyroglobulin in TS_69_2.\n",
      "Tomogram shape for TS_6_4 (z, y, x): (184, 630, 630)\n",
      "Loaded 10 points for virus-like-particle in TS_6_4.\n",
      "Loaded 58 points for apo-ferritin in TS_6_4.\n",
      "Loaded 9 points for beta-amylase in TS_6_4.\n",
      "Loaded 12 points for beta-galactosidase in TS_6_4.\n",
      "Loaded 74 points for ribosome in TS_6_4.\n",
      "Loaded 30 points for thyroglobulin in TS_6_4.\n",
      "Tomogram shape for TS_6_6 (z, y, x): (184, 630, 630)\n",
      "Loaded 19 points for virus-like-particle in TS_6_6.\n",
      "Loaded 41 points for apo-ferritin in TS_6_6.\n",
      "Loaded 14 points for beta-amylase in TS_6_6.\n",
      "Loaded 11 points for beta-galactosidase in TS_6_6.\n",
      "Loaded 23 points for ribosome in TS_6_6.\n",
      "Loaded 35 points for thyroglobulin in TS_6_6.\n",
      "Tomogram shape for TS_73_6 (z, y, x): (184, 630, 630)\n",
      "Loaded 22 points for virus-like-particle in TS_73_6.\n",
      "Loaded 95 points for apo-ferritin in TS_73_6.\n",
      "Loaded 12 points for beta-amylase in TS_73_6.\n",
      "Loaded 14 points for beta-galactosidase in TS_73_6.\n",
      "Loaded 46 points for ribosome in TS_73_6.\n",
      "Loaded 28 points for thyroglobulin in TS_73_6.\n",
      "Tomogram shape for TS_86_3 (z, y, x): (184, 630, 630)\n",
      "Loaded 29 points for virus-like-particle in TS_86_3.\n",
      "Loaded 64 points for apo-ferritin in TS_86_3.\n",
      "Loaded 9 points for beta-amylase in TS_86_3.\n",
      "Loaded 23 points for beta-galactosidase in TS_86_3.\n",
      "Loaded 55 points for ribosome in TS_86_3.\n",
      "Loaded 45 points for thyroglobulin in TS_86_3.\n",
      "Tomogram shape for TS_99_9 (z, y, x): (184, 630, 630)\n",
      "Loaded 13 points for virus-like-particle in TS_99_9.\n",
      "Loaded 36 points for apo-ferritin in TS_99_9.\n",
      "Loaded 21 points for beta-amylase in TS_99_9.\n",
      "Loaded 24 points for beta-galactosidase in TS_99_9.\n",
      "Loaded 65 points for ribosome in TS_99_9.\n",
      "Loaded 49 points for thyroglobulin in TS_99_9.\n",
      "Combined tomogram shape (z, y, x): (1288, 630, 630)\n",
      "Total number of particles: 1269\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------LOADING TOMOGRAM DATA AND PARTICLE COORDINATES-----------------#\n",
    "\n",
    "# Define the experiment runs to load\n",
    "experiment_runs = [\"TS_5_4\", \"TS_69_2\", \"TS_6_4\", \"TS_6_6\", \"TS_73_6\", \"TS_86_3\", \"TS_99_9\"]\n",
    "particle_types = {\"virus-like-particle\": 1, \"apo-ferritin\": 2, \"beta-amylase\": 3, \"beta-galactosidase\": 4, \"ribosome\": 5, \"thyroglobulin\": 6}\n",
    "particle_radii = {\"virus-like-particle\": 135, \"apo-ferritin\": 60, \"beta-amylase\": 65, \"beta-galactosidase\": 90, \"ribosome\": 150, \"thyroglobulin\": 130}\n",
    "voxel_spacing = [10.0, 10.0, 10.0]  # 10 angstroms per voxel\n",
    "\n",
    "# Initialize lists to store combined data\n",
    "combined_tomogram_data = []\n",
    "combined_particle_coords = {pt: [] for pt in particle_types}\n",
    "\n",
    "# Track the cumulative z-depth for coordinate translation\n",
    "cumulative_z_depth = 0\n",
    "\n",
    "# Load and combine data from all experiment runs\n",
    "for experiment_run in experiment_runs:\n",
    "    zarr_file_path = os.path.join(\"train\", \"static\", \"ExperimentRuns\", experiment_run, \"VoxelSpacing10.000\", \"denoised.zarr\")\n",
    "    json_base_path = os.path.join(\"train\", \"overlay\", \"ExperimentRuns\", experiment_run, \"Picks\")\n",
    "\n",
    "    # Load the Zarr file\n",
    "    try:\n",
    "        tomogram = zarr.open(zarr_file_path, mode=\"r\")\n",
    "        tomogram_data = tomogram[\"0\"][:]  # Load into memory as a NumPy array\n",
    "        print(f\"Tomogram shape for {experiment_run} (z, y, x):\", tomogram_data.shape)\n",
    "        tomogram_data = (tomogram_data - tomogram_data.mean()) / tomogram_data.std()\n",
    "        combined_tomogram_data.append(tomogram_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Zarr file for {experiment_run}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Load and transform particle coordinates for all types\n",
    "    for particle_type in particle_types:\n",
    "        json_file_path = os.path.join(json_base_path, f\"{particle_type}.json\")\n",
    "        try:\n",
    "            with open(json_file_path, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "            points = data[\"points\"]\n",
    "\n",
    "            # Convert from real-world coordinates (angstroms) to voxel indices and reorder to (z, y, x)\n",
    "            coords = np.round([\n",
    "                [\n",
    "                    (p[\"location\"][\"z\"] / voxel_spacing[0]) + cumulative_z_depth,\n",
    "                    p[\"location\"][\"y\"] / voxel_spacing[1],\n",
    "                    p[\"location\"][\"x\"] / voxel_spacing[2],\n",
    "                ]\n",
    "                for p in points\n",
    "            ]).astype(int)\n",
    "            combined_particle_coords[particle_type].extend(coords)\n",
    "            print(f\"Loaded {len(coords)} points for {particle_type} in {experiment_run}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading JSON file for {particle_type} in {experiment_run}: {e}\")\n",
    "\n",
    "    # Update cumulative_z_depth for the next tomogram\n",
    "    cumulative_z_depth += tomogram_data.shape[0]\n",
    "\n",
    "# Combine all tomogram data into a single array\n",
    "combined_tomogram_data = np.concatenate(combined_tomogram_data, axis=0)\n",
    "print(\"Combined tomogram shape (z, y, x):\", combined_tomogram_data.shape)\n",
    "\n",
    "# Print total number of particles\n",
    "total_particles = sum(len(coords) for coords in combined_particle_coords.values())\n",
    "print(f\"Total number of particles: {total_particles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label cube precomputed.\n"
     ]
    }
   ],
   "source": [
    "# -------------PRECOMPUTE LABEL CUBE-----------------#\n",
    "label_cube = np.zeros(combined_tomogram_data.shape, dtype=int)\n",
    "\n",
    "for particle_type, coords in combined_particle_coords.items():\n",
    "    particle_id = particle_types[particle_type]\n",
    "    radius = int(particle_radii[particle_type] / voxel_spacing[0])  # Convert radius to voxel units\n",
    "    radius = 3\n",
    "    for coord in coords:\n",
    "        z, y, x = coord.astype(int)\n",
    "\n",
    "        # Define the bounding box for the particle\n",
    "        z_min, z_max = max(0, z - radius), min(label_cube.shape[0], z + radius + 1)\n",
    "        y_min, y_max = max(0, y - radius), min(label_cube.shape[1], y + radius + 1)\n",
    "        x_min, x_max = max(0, x - radius), min(label_cube.shape[2], x + radius + 1)\n",
    "\n",
    "        # Mark the region with the particle ID\n",
    "        label_cube[z_min:z_max, y_min:y_max, x_min:x_max] = particle_id\n",
    "\n",
    "print(\"Label cube precomputed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize the tomogram and label cube\n",
    "def visualize_tomogram_and_labels(tomogram_data, label_cube):\n",
    "    \"\"\"\n",
    "    Visualize the combined tomogram data and the label cube using napari.\n",
    "\n",
    "    Parameters:\n",
    "        tomogram_data (numpy.ndarray): The combined tomogram data array.\n",
    "        label_cube (numpy.ndarray): The label cube corresponding to the tomogram data.\n",
    "    \"\"\"\n",
    "    # Initialize the napari viewer\n",
    "    viewer = napari.Viewer()\n",
    "\n",
    "    # Add the tomogram data as the first layer\n",
    "    viewer.add_image(\n",
    "        tomogram_data,\n",
    "        name=\"Tomogram Data\",\n",
    "        contrast_limits=[np.min(tomogram_data), np.max(tomogram_data)],  # Adjust contrast\n",
    "        colormap=\"gray\",\n",
    "    )\n",
    "\n",
    "    # Add the label cube as the second layer\n",
    "    viewer.add_labels(\n",
    "        label_cube,\n",
    "        name=\"Label Cube\",\n",
    "        opacity=0.5,  # Make it slightly transparent to see the tomogram data underneath\n",
    "    )\n",
    "\n",
    "    # Start the napari event loop\n",
    "    napari.run()\n",
    "\n",
    "\n",
    "# Call the function to visualize\n",
    "visualize_tomogram_and_labels(combined_tomogram_data, label_cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 398 cubes for the dataset. Where 362 contain particles and 36 do not.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------Combine tomograms and sample cubes with particles in it-----------------#\n",
    "\n",
    "# Dimensions of the combined tomogram data\n",
    "data_shape = combined_tomogram_data.shape\n",
    "cube_size = (96, 96, 96)\n",
    "background_id = 0\n",
    "\n",
    "# Calculate the number of cubes in each dimension\n",
    "num_cubes_z = data_shape[0] // cube_size[0]\n",
    "num_cubes_y = data_shape[1] // cube_size[1]\n",
    "num_cubes_x = data_shape[2] // cube_size[2]\n",
    "\n",
    "# Create a list of all possible cube indices\n",
    "cubes = []\n",
    "particle_cubes = []\n",
    "non_particle_cubes = []\n",
    "\n",
    "for z in range(num_cubes_z):\n",
    "    for y in range(num_cubes_y):\n",
    "        for x in range(num_cubes_x):\n",
    "            cubes.append((z, y, x))\n",
    "\n",
    "# Separate cubes into particle-containing and non-particle cubes\n",
    "def contains_particle(cube_start, label_cube):\n",
    "    z_start, y_start, x_start = cube_start\n",
    "    z_end, y_end, x_end = z_start + cube_size[0], y_start + cube_size[1], x_start + cube_size[2]\n",
    "    return np.any(label_cube[z_start:z_end, y_start:y_end, x_start:x_end] > 0)\n",
    "\n",
    "for cz, cy, cx in cubes:\n",
    "    cube_start = (cz * cube_size[0], cy * cube_size[1], cx * cube_size[2])\n",
    "    if contains_particle(cube_start, label_cube):\n",
    "        particle_cubes.append((cz, cy, cx))\n",
    "    else:\n",
    "        non_particle_cubes.append((cz, cy, cx))\n",
    "\n",
    "# Limit non-particle cubes to 10% of the dataset\n",
    "num_non_particle_cubes = int(len(particle_cubes) * 0.1)\n",
    "selected_non_particle_cubes = random.sample(non_particle_cubes, num_non_particle_cubes)\n",
    "selected_cubes = particle_cubes + selected_non_particle_cubes\n",
    "print(f\"Selected {len(selected_cubes)} cubes for the dataset. Where {len(particle_cubes)} contain particles and {len(selected_non_particle_cubes)} do not.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing the combined tomogram with particles...\n"
     ]
    }
   ],
   "source": [
    "# ------------------- VISUALIZE Combined Tomogram Data ----------------------------#\n",
    "\n",
    "# Define a color map for label IDs\n",
    "label_colors = {\n",
    "    1: \"red\",        # virus-like-particle\n",
    "    2: \"green\",      # apo-ferritin\n",
    "    3: \"blue\",       # beta-amylase\n",
    "    4: \"yellow\",     # beta-galactosidase\n",
    "    5: \"magenta\",    # ribosome\n",
    "    6: \"cyan\",       # thyroglobulin\n",
    "}\n",
    "\n",
    "# Function to visualize the combined tomogram with particles in 3D using napari\n",
    "def visualize_combined_tomogram(tomogram_data, particle_coords):\n",
    "    # Create a napari viewer\n",
    "    viewer = napari.Viewer()\n",
    "\n",
    "    # Add the combined tomogram data as a 3D volume\n",
    "    viewer.add_image(tomogram_data, name=\"Combined Tomogram\")\n",
    "\n",
    "    # Collect all particle coordinates and their label IDs\n",
    "    all_particles = []\n",
    "    all_labels = []\n",
    "    for particle_type, coords in particle_coords.items():\n",
    "        label_id = particle_types[particle_type]\n",
    "        all_particles.extend(coords)\n",
    "        all_labels.extend([label_id] * len(coords))\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    all_particles = np.array(all_particles)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Assign colors to each particle based on its label ID\n",
    "    colors = [label_colors[label] for label in all_labels]\n",
    "\n",
    "    # Add the particles as a 3D points layer with different colors\n",
    "    if all_particles.size > 0:\n",
    "        viewer.add_points(\n",
    "            all_particles,\n",
    "            name=\"Particles\",\n",
    "            face_color=colors,\n",
    "            size=5,\n",
    "            opacity=0.8,\n",
    "        )\n",
    "\n",
    "    # Start the napari event loop\n",
    "    napari.run()\n",
    "\n",
    "# Visualize the combined tomogram with particles\n",
    "print(\"Visualizing the combined tomogram with particles...\")\n",
    "visualize_combined_tomogram(combined_tomogram_data, combined_particle_coords)\n",
    "# ---------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing 10 selected cubes with particles...\n"
     ]
    }
   ],
   "source": [
    "def visualize_selected_cubes(tomogram_data, particle_coords, selected_cubes, cube_size):\n",
    "    # Create a napari viewer\n",
    "    viewer = napari.Viewer()\n",
    "\n",
    "    # Iterate through the 10 selected cubes and visualize them\n",
    "    for idx, (cz, cy, cx) in enumerate(selected_cubes[:10]):  # Limit to 10 cubes\n",
    "        # Define cube boundaries\n",
    "        z_start, y_start, x_start = cz * cube_size[0], cy * cube_size[1], cx * cube_size[2]\n",
    "        z_end, y_end, x_end = z_start + cube_size[0], y_start + cube_size[1], x_start + cube_size[2]\n",
    "\n",
    "        # Extract cube data from the tomogram\n",
    "        cube_data = tomogram_data[z_start:z_end, y_start:y_end, x_start:x_end]\n",
    "\n",
    "        # Collect particle coordinates and labels within the cube\n",
    "        cube_particles = []\n",
    "        cube_labels = []\n",
    "        for particle_type, coords in particle_coords.items():\n",
    "            label_id = particle_types[particle_type]\n",
    "            for coord in coords:\n",
    "                z, y, x = coord.astype(int)\n",
    "                if z_start <= z < z_end and y_start <= y < y_end and x_start <= x < x_end:\n",
    "                    # Adjust coordinates to cube-local space\n",
    "                    cube_particles.append([z - z_start, y - y_start, x - x_start])\n",
    "                    cube_labels.append(label_id)\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        cube_particles = np.array(cube_particles)\n",
    "        cube_labels = np.array(cube_labels)\n",
    "\n",
    "        # Assign colors to each particle based on its label ID\n",
    "        colors = [label_colors[label] for label in cube_labels]\n",
    "\n",
    "        # Add the cube data as a volume\n",
    "        viewer.add_image(cube_data, name=f\"Cube {idx + 1}\", colormap=\"gray\")\n",
    "\n",
    "        # Add the particles as a points layer\n",
    "        if cube_particles.size > 0:\n",
    "            viewer.add_points(\n",
    "                cube_particles,\n",
    "                name=f\"Particles in Cube {idx + 1}\",\n",
    "                face_color=colors,\n",
    "                size=5,\n",
    "                opacity=0.8,\n",
    "            )\n",
    "\n",
    "    # Start the napari event loop\n",
    "    napari.run()\n",
    "\n",
    "# Visualize the first 10 selected cubes\n",
    "print(\"Visualizing 10 selected cubes with particles...\")\n",
    "visualize_selected_cubes(combined_tomogram_data, combined_particle_coords, selected_cubes, cube_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTER = 0\n",
    "\n",
    "class DataCreator():\n",
    "    def __init__(self, tomogram_data, label_cube, selected_cubes):\n",
    "        self.tomogram_data = tomogram_data\n",
    "        self.label_cube = label_cube\n",
    "        self.selected_cubes = selected_cubes\n",
    "        self.cube_size = (96, 96, 96)\n",
    "        self.subcube_size = (6, 6, 6)\n",
    "        self.background_id = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.selected_cubes)\n",
    "\n",
    "    def getitem(self, idx):\n",
    "        cz, cy, cx = self.selected_cubes[idx]\n",
    "        z_start, z_end = cz * self.cube_size[0], (cz + 1) * self.cube_size[0]\n",
    "        y_start, y_end = cy * self.cube_size[1], (cy + 1) * self.cube_size[1]\n",
    "        x_start, x_end = cx * self.cube_size[2], (cx + 1) * self.cube_size[2]\n",
    "\n",
    "        cube_data = self.tomogram_data[z_start:z_end, y_start:y_end, x_start:x_end]\n",
    "        labels = self.generate_labels(z_start, y_start, x_start)\n",
    "\n",
    "        cube_data = np.expand_dims(cube_data, axis=0)  # Add channel dimension\n",
    "        return (\n",
    "            torch.tensor(cube_data, dtype=torch.float32),\n",
    "            torch.tensor(labels, dtype=torch.int64),\n",
    "        )\n",
    "\n",
    "    def generate_labels(self, z_start, y_start, x_start):\n",
    "        global COUNTER\n",
    "        mini_cube_labels = []\n",
    "        \n",
    "        for z in range(0, self.cube_size[2], self.subcube_size[2]):  # Width first\n",
    "            for y in range(0, self.cube_size[1], self.subcube_size[1]):  # Height second\n",
    "                for x in range(0, self.cube_size[0], self.subcube_size[0]):  # Depth last\n",
    "                    mini_cube = self.label_cube[\n",
    "                        z_start + z:z_start + z + self.subcube_size[0],\n",
    "                        y_start + y:y_start + y + self.subcube_size[1],\n",
    "                        x_start + x:x_start + x + self.subcube_size[2],\n",
    "                    ]\n",
    "                    unique, counts = np.unique(mini_cube, return_counts=True)\n",
    "                    label_coverage = dict(zip(unique, counts))\n",
    "                    total_voxels = np.prod(self.subcube_size)\n",
    "\n",
    "                    dominant_label = self.background_id\n",
    "                    max_coverage = 0\n",
    "\n",
    "                    for label, coverage in label_coverage.items():\n",
    "                        if label != self.background_id and coverage / total_voxels >= 0.3 and coverage > max_coverage:\n",
    "                            dominant_label = label\n",
    "                            max_coverage = coverage\n",
    "                    if dominant_label !=0 : COUNTER += 1\n",
    "                    mini_cube_labels.append(dominant_label)\n",
    "\n",
    "        return np.array(mini_cube_labels)\n",
    "\n",
    "    def generate_data(self):\n",
    "        tomogram_data = torch.zeros((len(self.selected_cubes), 1, *self.cube_size))\n",
    "        segmentation_labels = torch.zeros((len(self.selected_cubes), int(self.cube_size[0]**3/self.subcube_size[0]**3)), dtype=torch.int64)\n",
    "\n",
    "        for idx in range(len(self.selected_cubes)):\n",
    "            data_tensor, label_tensor= self.getitem(idx)\n",
    "            tomogram_data[idx] = data_tensor\n",
    "            segmentation_labels[idx] = label_tensor\n",
    "        return tomogram_data, segmentation_labels\n",
    "\n",
    "# Data Creator\n",
    "data_creator = DataCreator(\n",
    "    combined_tomogram_data, label_cube, selected_cubes\n",
    ")\n",
    "\n",
    "input_data, segmentation_labels = data_creator.generate_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def upscale_labels(label_tensor, original_shape=(90, 90, 90), subcube_shape=(16, 16, 16)):\n",
    "    \"\"\"\n",
    "    Upscale the labels from (4096,) to (16, 16, 16) and then to (90, 90, 90).\n",
    "    \"\"\"\n",
    "    # Step 1: Reshape the flat label tensor to (16, 16, 16)\n",
    "    reshaped_labels = label_tensor.view(subcube_shape)\n",
    "\n",
    "    # Step 2: Upscale to (90, 90, 90) by assigning subcube regions\n",
    "    upscaled_labels = np.zeros(original_shape, dtype=int)\n",
    "    subcube_size = original_shape[0] // subcube_shape[0]  # Typically 6 if (90, 90, 90) and (16, 16, 16)\n",
    "\n",
    "    for z in range(subcube_shape[0]):\n",
    "        for y in range(subcube_shape[1]):\n",
    "            for x in range(subcube_shape[2]):\n",
    "                label = reshaped_labels[z, y, x]\n",
    "                upscaled_labels[\n",
    "                    z * subcube_size : (z + 1) * subcube_size,\n",
    "                    y * subcube_size : (y + 1) * subcube_size,\n",
    "                    x * subcube_size : (x + 1) * subcube_size\n",
    "                ] = label\n",
    "\n",
    "    return upscaled_labels\n",
    "\n",
    "def visualize_with_napari(inputs, labels, sample_idx=0):\n",
    "    \"\"\"\n",
    "    Visualize the input tomogram and the corresponding labels using napari.\n",
    "    \n",
    "    Parameters:\n",
    "        inputs (torch.Tensor): Input tomogram data of shape (N, 1, 90, 90, 90).\n",
    "        labels (torch.Tensor): Segmentation labels of shape (N, 4096).\n",
    "        sample_idx (int): Index of the sample to visualize.\n",
    "    \"\"\"\n",
    "    # Get the input data and corresponding label\n",
    "    input_sample = inputs[sample_idx].squeeze(0).cpu().numpy()  # Shape: (90, 90, 90)\n",
    "    label_sample = labels[sample_idx].cpu()\n",
    "\n",
    "    # Upscale the labels from (4096,) -> (16, 16, 16) -> (90, 90, 90)\n",
    "    upscaled_labels = upscale_labels(label_sample)\n",
    "\n",
    "\n",
    "    viewer = napari.Viewer()\n",
    "\n",
    "    # Add the input tomogram data as grayscale image\n",
    "    viewer.add_image(input_sample, name=f\"Sample {sample_idx} - Input\", colormap=\"gray\")\n",
    "\n",
    "    # Add the upscaled labels as an overlay\n",
    "    viewer.add_labels(upscaled_labels, name=f\"Sample {sample_idx} - Labels\")\n",
    "\n",
    "    # Optionally, you can adjust opacity or blending mode for better visualization:\n",
    "    viewer.layers[f\"Sample {sample_idx} - Labels\"].opacity = 0.5  # Semi-transparent overlay\n",
    "\n",
    "# Example usage:\n",
    "# Visualize the first sample from the generated data\n",
    "visualize_with_napari(input_data, segmentation_labels, sample_idx=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "        # regularization\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        # nh is \"number of heads\", hs is \"head size\", and C (number of channels) = nh * hs\n",
    "        # e.g. in GPT-2 (124M), n_head=11, hs=64, so nh*hs=C=768 channels in the Transformer\n",
    "        qkv = self.c_attn(x)\n",
    "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        y = F.scaled_dot_product_attention(q, k, v, is_causal=False) # flash attention\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "        # output projection\n",
    "        y = self.c_proj(y)\n",
    "        return y\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd)\n",
    "        self.gelu    = nn.GELU()\n",
    "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        return x\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = SelfAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_layers, decoder_layer):\n",
    "        super().__init__()\n",
    "        self.layers = clones(decoder_layer, num_layers)\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, tgt):\n",
    "        output = tgt\n",
    "\n",
    "        for mod in self.layers:\n",
    "            output = mod(output)\n",
    "        return output\n",
    "\n",
    "class CnnTokenizer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.conv_1 = nn.Conv3d(1, config.n_embd //  2, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn_1 = nn.BatchNorm3d(config.n_embd // 2)\n",
    "        self.dropout_1 = nn.Dropout(0.2)\n",
    "        self.conv_2 = nn.Conv3d(config.n_embd // 2, config.n_embd // 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn_2 = nn.BatchNorm3d(config.n_embd // 2)\n",
    "        self.dropout_2 = nn.Dropout(0.2)\n",
    "        self.conv_3 = nn.Conv3d(config.n_embd // 2, config.n_embd, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn_3 = nn.BatchNorm3d(config.n_embd)\n",
    "        self.dropout_3 = nn.Dropout(0.2)\n",
    "        self.downsize = nn.Conv3d(config.n_embd, config.n_embd, kernel_size=3, stride=2, padding=1)\n",
    "        self.slice = nn.Conv3d(config.n_embd, config.n_embd, kernel_size=config.token_width, stride=config.token_width, padding=0) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        # print(f\"shape after conv_1: {x.shape}\")\n",
    "        x = self.bn_1(x)\n",
    "        x = F.gelu(x)\n",
    "        # x = self.dropout_1(x)\n",
    "\n",
    "        x = self.conv_2(x)\n",
    "        # print(f\"shape after conv_2: {x.shape}\")\n",
    "        x = self.bn_2(x)\n",
    "        x = F.gelu(x)\n",
    "        # x = self.dropout_2(x)\n",
    "\n",
    "        x = self.conv_3(x)\n",
    "        # print(f\"shape after conv_3: {x.shape}\")\n",
    "        x = self.bn_3(x)\n",
    "        x = F.gelu(x)\n",
    "        # x = self.dropout_3(x)\n",
    "        \n",
    "        x = self.downsize(x)\n",
    "        # print(f\"shape after downsize: {x.shape}\")\n",
    "        x = self.slice(x)\n",
    "        # print(f\"shape after slice: {x.shape}\")\n",
    "        x = x.reshape(x.size(0), self.config.n_embd, -1).transpose(1, 2)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class LinearTokenizer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.tokenizer = nn.Conv3d(\n",
    "            in_channels=1,  # Input channels (C=1)\n",
    "            out_channels=config.n_embd,\n",
    "            kernel_size=config.token_width,\n",
    "            stride=config.token_width,\n",
    "            padding=0,\n",
    "            bias=True  # Optional\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (B, 1, D=96, H=96, W=96)\n",
    "        x = self.tokenizer(x)  # Output shape: (B, n_embd, D_blocks=8, H_blocks=8, W_blocks=8)\n",
    "        x = x.permute(0, 2, 3, 4, 1)  # (B, D_blocks, H_blocks, W_blocks, n_embd)\n",
    "        x = x.view(x.size(0), -1, x.size(-1))  # (B, D_blocks*H_blocks*W_blocks=512, n_embd)\n",
    "        # print(f\"Tokenizer output shape: {x.shape}\")\n",
    "        return x\n",
    "@dataclass\n",
    "class CNNConfig:\n",
    "    block_size: int = 8**3 # max sequence length\n",
    "    token_width: int = 6 # width of the cube\n",
    "    n_layer: int = 4 # number of layers\n",
    "    n_head: int = 16 # number of heads\n",
    "    n_embd: int = 256 # embedding dimension\n",
    "\n",
    "@dataclass\n",
    "class LinearConfig:\n",
    "    block_size: int = int((96**3)/(6**3)) # max sequence length\n",
    "    token_width: int = 6 # width of the cube\n",
    "    n_layer: int = 8 # number of layers\n",
    "    n_head: int = 16 # number of heads\n",
    "    n_embd: int = 128 # embedding dimension\n",
    "\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.tokenizer = LinearTokenizer(config)\n",
    "        self.positional_embedding = nn.Parameter(torch.zeros(config.block_size, config.n_embd))\n",
    "        self.transformer = Transformer(config.n_layer, TransformerBlock(config))\n",
    "        self.decoder = nn.Linear(config.n_embd, len(particle_types) + 1)  # Output layer\n",
    "\n",
    "    def ff(self, x):\n",
    "        x = self.tokenizer(x) # (N, 1, 96, 96, 96) -> (N, 8 * 8 * 8, n_embd)\n",
    "        x = x + self.positional_embedding # (N, n_embd, 8, 8, 8) -> (N, n_embd, 512) -> (N, 512, n_embd)\n",
    "        x = self.transformer(x) # (N, 512, n_embd) -> (N, 512, n_embd)\n",
    "        x = self.decoder(x) # (N, 512, n_embd) -> (N, 512, 7)        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):   \n",
    "        return self.ff(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of parameters: 2.17e+06\n",
      "Epoch 1, Loss: 2.4415\n",
      "Epoch 2, Loss: 2.4301\n",
      "Epoch 3, Loss: 2.4030\n",
      "Epoch 4, Loss: 2.3751\n",
      "Epoch 5, Loss: 2.3804\n",
      "Epoch 6, Loss: 2.3978\n",
      "Epoch 7, Loss: 2.4243\n",
      "Epoch 8, Loss: 2.3816\n",
      "Epoch 9, Loss: 2.3488\n",
      "Epoch 10, Loss: 2.3569\n",
      "Epoch 11, Loss: 2.3713\n",
      "Epoch 12, Loss: 2.3695\n",
      "Epoch 13, Loss: 2.3981\n",
      "Epoch 14, Loss: 2.3652\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 187\u001b[0m\n\u001b[0;32m    184\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    185\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 187\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ariel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\monai\\data\\meta_tensor.py:282\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    281\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 282\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;66;03m#     return ret\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _not_requiring_metadata(ret):\n",
      "File \u001b[1;32mc:\\Users\\ariel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:1386\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m-> 1386\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[0;32m   1388\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ------------------- Contrastive Learning  ------------------------#\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class ContrastiveTomogramDataset(Dataset):\n",
    "    def __init__(self, tomogram_data, selected_cubes, transform=None):\n",
    "        self.tomogram_data = tomogram_data\n",
    "        self.selected_cubes = selected_cubes\n",
    "        self.cube_size = (96, 96, 96)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.selected_cubes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cz, cy, cx = self.selected_cubes[idx]\n",
    "        z_start = cz * self.cube_size[0]\n",
    "        y_start = cy * self.cube_size[1]\n",
    "        x_start = cx * self.cube_size[2]\n",
    "\n",
    "        # Extract original cube\n",
    "        cube = self.tomogram_data[\n",
    "            z_start:z_start+self.cube_size[0],\n",
    "            y_start:y_start+self.cube_size[1],\n",
    "            x_start:x_start+self.cube_size[2]\n",
    "        ]\n",
    "        \n",
    "        # Create two augmented views\n",
    "        return {\n",
    "            'view1': self._apply_transforms(cube),\n",
    "            'view2': self._apply_transforms(cube)\n",
    "        }\n",
    "\n",
    "    def _apply_transforms(self, cube):\n",
    "        cube = np.expand_dims(cube, axis=0)  # Add channel dim\n",
    "        cube = torch.tensor(cube, dtype=torch.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            data = {'image': cube}\n",
    "            data = self.transform(data)\n",
    "            return data['image']\n",
    "        return cube\n",
    "\n",
    "# Define stronger augmentations for contrastive learning\n",
    "contrastive_transforms = Compose([\n",
    "    RandFlipd(keys=['image'], prob=0.5, spatial_axis=0),\n",
    "    RandFlipd(keys=['image'], prob=0.5, spatial_axis=1),\n",
    "    RandFlipd(keys=['image'], prob=0.5, spatial_axis=2),\n",
    "    RandRotated(\n",
    "        keys=['image'],\n",
    "        prob=0.8,\n",
    "        range_x=15.0,\n",
    "        range_y=15.0,\n",
    "        range_z=15.0,\n",
    "        mode='bilinear',\n",
    "        padding_mode='zeros'\n",
    "    ),\n",
    "    RandAdjustContrastd(keys=['image'], prob=0.5, gamma=(0.7, 1.3)),\n",
    "    RandGaussianNoised(keys=['image'], prob=0.5, std=0.1),\n",
    "])\n",
    "\n",
    "\n",
    "class ContrastiveModel(BaseModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        # Summarizer token\n",
    "        self.summarizer = nn.Parameter(torch.zeros(1, 1, config.n_embd))\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(config.n_embd, config.n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(config.n_embd, 128)  # Project to lower-dimensional space\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenizer(x) # (N, 1, 96, 96, 96) -> (N, 8 * 8 * 8, n_embd)\n",
    "        x = x + self.positional_embedding # (N, n_embd, 8, 8, 8) -> (N, n_embd, n_tokens) -> (N, n_tokens, n_embd)\n",
    "        \n",
    "        # Append Summarizer token\n",
    "        x = torch.cat([self.summarizer.repeat(x.size(0), 1, 1), x], dim=1)\n",
    "        \n",
    "        # Build representation using transformer\n",
    "        x = self.transformer(x) # (N, n_tokens + 1, n_embd) -> (N, n_tokens + 1, n_embd)\n",
    "        \n",
    "        # Extract the summarizer token\n",
    "        x = x[:, 0, :]  \n",
    "        # Project to contrastive space\n",
    "        return self.projection_head(x)\n",
    "\n",
    "# NT-Xent Loss (Normalized Temperature-scaled Cross Entropy Loss)\n",
    "class NTXentLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, z1, z2):\n",
    "        assert z1.size() == z2.size()\n",
    "        # Concatenate both views\n",
    "        z = torch.cat([z1, z2], dim=0)\n",
    "        z = F.normalize(z, p=2, dim=1)\n",
    "        size = z.size(0)\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        sim = torch.mm(z, z.T) / self.temperature\n",
    "        logits = torch.exp(sim)\n",
    "        logits = torch.masked_fill(logits, torch.eye(size, dtype=torch.bool, device=device), 0)\n",
    "        logits = logits / torch.sum(logits, dim=1, keepdim=True)\n",
    "\n",
    "        labels = torch.remainder(torch.arange(size) + size//2, size).to(device)\n",
    "        \n",
    "        return self.criterion(logits, labels)\n",
    "\n",
    "config = LinearConfig()\n",
    "\n",
    "# Create dataset and loaders\n",
    "contrastive_dataset = ContrastiveTomogramDataset(\n",
    "    combined_tomogram_data,\n",
    "    selected_cubes,\n",
    "    transform=contrastive_transforms\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(contrastive_dataset, batch_size=6, shuffle=True)\n",
    "\n",
    "# Initialize model and loss\n",
    "model = ContrastiveModel(config).to(device)\n",
    "# print the # of parameters\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):.2e}\")\n",
    "try:\n",
    "    model.load_state_dict(torch.load(\"contrastive_model.pth\"))\n",
    "    print(\"Loaded pre-trained model.\")\n",
    "except:\n",
    "    pass\n",
    "criterion = NTXentLoss(temperature=0.1).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        # Get both views\n",
    "        x1 = batch['view1'].to(device)\n",
    "        x2 = batch['view2'].to(device)\n",
    "        # Forward passes\n",
    "        z1 = model(x1)\n",
    "        z2 = model(x2)\n",
    "        # Compute loss\n",
    "        loss = criterion(z1, z2)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), f\"contrastive_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"contrastive_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationModel(ContrastiveModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "    \n",
    "    def ff_without_summarizer(self, x):\n",
    "        # ContrastiveModel inherits the ff (feedforward without summarizer) method from the BaseModel\n",
    "        return self.ff(x)\n",
    "    \n",
    "    def ff_with_summarizer(self, x):\n",
    "        x = self.tokenizer(x) # (N, 1, 96, 96, 96) -> (N, 8 * 8 * 8, n_embd)\n",
    "        x = x + self.positional_embedding # (N, n_embd, 8, 8, 8) -> (N, n_embd, n_tokens) -> (N, n_tokens, n_embd)\n",
    "        \n",
    "        # Append Summarizer token\n",
    "        x = torch.cat([self.summarizer.repeat(x.size(0), 1, 1), x], dim=1)\n",
    "        \n",
    "        # Build representation using transformer\n",
    "        x = self.transformer(x) # (N, n_tokens + 1, n_embd) -> (N, n_tokens + 1, n_embd)     \n",
    "\n",
    "        # Classify\n",
    "        x = self.decoder(x[:, 1:, :])\n",
    "        return x       \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ff_with_summarizer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(particle_dataset_mini_cubes): 459\n",
      "Cube Data Shape: torch.Size([1, 96, 96, 96])\n",
      "Labels Shape: torch.Size([4096])\n"
     ]
    }
   ],
   "source": [
    "# -------------DATASET IMPLEMENTATION-----------------#\n",
    "class TomogramDatasetMiniCubes(Dataset):\n",
    "    def __init__(self, tomogram_data, label_cube, selected_cubes):\n",
    "        self.tomogram_data = tomogram_data\n",
    "        self.label_cube = label_cube\n",
    "        self.selected_cubes = selected_cubes\n",
    "        self.cube_size = (96, 96, 96)\n",
    "        self.subcube_size = (6, 6, 6)\n",
    "        self.background_id = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.selected_cubes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cz, cy, cx = self.selected_cubes[idx]\n",
    "        z_start, z_end = cz * self.cube_size[0], (cz + 1) * self.cube_size[0]\n",
    "        y_start, y_end = cy * self.cube_size[1], (cy + 1) * self.cube_size[1]\n",
    "        x_start, x_end = cx * self.cube_size[2], (cx + 1) * self.cube_size[2]\n",
    "\n",
    "        cube_data = self.tomogram_data[z_start:z_end, y_start:y_end, x_start:x_end]\n",
    "        labels = self.generate_labels(z_start, y_start, x_start)\n",
    "\n",
    "        cube_data = np.expand_dims(cube_data, axis=0)  # Add channel dimension\n",
    "        return (\n",
    "            torch.tensor(cube_data, dtype=torch.float32),\n",
    "            torch.tensor(labels, dtype=torch.int64),\n",
    "        )\n",
    "\n",
    "    def generate_labels(self, z_start, y_start, x_start):\n",
    "        mini_cube_labels = []\n",
    "        for z in range(0, self.cube_size[0], self.subcube_size[0]):\n",
    "            for y in range(0, self.cube_size[1], self.subcube_size[1]):\n",
    "                for x in range(0, self.cube_size[2], self.subcube_size[2]):\n",
    "                    mini_cube = self.label_cube[\n",
    "                        z_start + z:z_start + z + self.subcube_size[0],\n",
    "                        y_start + y:y_start + y + self.subcube_size[1],\n",
    "                        x_start + x:x_start + x + self.subcube_size[2],\n",
    "                    ]\n",
    "                    unique, counts = np.unique(mini_cube, return_counts=True)\n",
    "                    label_coverage = dict(zip(unique, counts))\n",
    "                    total_voxels = np.prod(self.subcube_size)\n",
    "\n",
    "                    dominant_label = self.background_id\n",
    "                    max_coverage = 0\n",
    "\n",
    "                    for label, coverage in label_coverage.items():\n",
    "                        if label != self.background_id and coverage / total_voxels >= 0.2 and coverage > max_coverage:\n",
    "                            dominant_label = label\n",
    "                            max_coverage = coverage\n",
    "\n",
    "                    mini_cube_labels.append(dominant_label)\n",
    "\n",
    "        return np.array(mini_cube_labels)\n",
    "\n",
    "\n",
    "# Create the dataset\n",
    "particle_dataset_mini_cubes = TomogramDatasetMiniCubes(\n",
    "    combined_tomogram_data, label_cube, selected_cubes\n",
    ")\n",
    "\n",
    "# Test the dataset\n",
    "cube_data, labels = particle_dataset_mini_cubes[200]\n",
    "print(f\"len(particle_dataset_mini_cubes): {len(particle_dataset_mini_cubes)}\")\n",
    "print(\"Cube Data Shape:\", cube_data.shape)  # Should be (1, 96, 96, 96)\n",
    "print(\"Labels Shape:\", labels.shape)        # Should be (4096,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first cube and its labels\n",
    "cube_data, labels = particle_dataset_mini_cubes[15]\n",
    "# print(labels)\n",
    "sample_data = cube_data.squeeze().numpy()  # Remove the channel dimension and convert to numpy array\n",
    "\n",
    "# Reshape the labels to match the mini-cube structure\n",
    "labels = labels.numpy().reshape((16, 16, 16)) \n",
    "\n",
    "# Create a napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Add the cube data as a 3D volume\n",
    "viewer.add_image(sample_data, name='Tomogram Cube')\n",
    "# viewer.add_image(np.ones_like(labels), name='Tomogram Cube')\n",
    "# Add the labels as a 3D labels layer\n",
    "# viewer.add_labels(labels, name='Mini-Cube Labels')\n",
    "\n",
    "# Start the napari event loop\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 1.57288820, Validation Loss: 1.28516688\n",
      "Epoch 2/200, Train Loss: 1.22700006, Validation Loss: 1.13906887\n",
      "Epoch 3/200, Train Loss: 1.10426477, Validation Loss: 1.05914401\n",
      "Epoch 4/200, Train Loss: 1.01188412, Validation Loss: 1.00391569\n",
      "Epoch 5/200, Train Loss: 0.96388233, Validation Loss: 0.96390377\n",
      "Epoch 6/200, Train Loss: 0.91687117, Validation Loss: 0.93749539\n",
      "Epoch 7/200, Train Loss: 0.89988101, Validation Loss: 0.91471113\n",
      "Epoch 8/200, Train Loss: 0.85953799, Validation Loss: 0.89410546\n",
      "Epoch 9/200, Train Loss: 0.84770854, Validation Loss: 0.88336953\n",
      "Epoch 10/200, Train Loss: 0.83550239, Validation Loss: 0.87119049\n",
      "Epoch 11/200, Train Loss: 0.81651862, Validation Loss: 0.86471188\n",
      "Epoch 12/200, Train Loss: 0.80328981, Validation Loss: 0.85287727\n",
      "Epoch 13/200, Train Loss: 0.79548920, Validation Loss: 0.85040967\n",
      "Epoch 14/200, Train Loss: 0.78357425, Validation Loss: 0.84379584\n",
      "Epoch 15/200, Train Loss: 0.77454838, Validation Loss: 0.84086553\n",
      "Epoch 16/200, Train Loss: 0.76965566, Validation Loss: 0.83647500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m segmentation_model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     22\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 23\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ariel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\ariel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\ariel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\ariel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ariel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[73], line 25\u001b[0m, in \u001b[0;36mTomogramDatasetMiniCubes.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     23\u001b[0m cube_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtomogram_data[z_start:z_end, y_start:y_end, x_start:x_end]\n\u001b[0;32m     24\u001b[0m cube_start \u001b[38;5;241m=\u001b[39m (z_start, y_start, x_start)\n\u001b[1;32m---> 25\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_mini_cube_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcube_start\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m cube_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(cube_data, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Add channel dimension\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m     29\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor(cube_data, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[0;32m     30\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor(labels, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64),\n\u001b[0;32m     31\u001b[0m )\n",
      "Cell \u001b[1;32mIn[73], line 44\u001b[0m, in \u001b[0;36mTomogramDatasetMiniCubes.create_mini_cube_labels\u001b[1;34m(self, cube_start)\u001b[0m\n\u001b[0;32m     38\u001b[0m             mini_cube_start \u001b[38;5;241m=\u001b[39m (z, y, x)\n\u001b[0;32m     39\u001b[0m             mini_cube_end \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     40\u001b[0m                 mini_cube_start[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubcube_size[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     41\u001b[0m                 mini_cube_start[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubcube_size[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     42\u001b[0m                 mini_cube_start[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubcube_size[\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m     43\u001b[0m             )\n\u001b[1;32m---> 44\u001b[0m             label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_label_for_mini_cube\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmini_cube_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmini_cube_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcube_start\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m             labels\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels\n",
      "Cell \u001b[1;32mIn[73]\u001b[0m, in \u001b[0;36mTomogramDatasetMiniCubes.get_label_for_mini_cube\u001b[1;34m(self, mini_cube_start, mini_cube_end, cube_start)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "segmentation_model = SegmentationModel(config).to(device)\n",
    "segmentation_model.load_state_dict(torch.load(\"contrastive_model.pth\"))\n",
    "\n",
    "# Write train and validation dataloader for segmentation using particle_dataset_mini_cubes\n",
    "train_size = int(0.8 * len(particle_dataset_mini_cubes))\n",
    "val_size = len(particle_dataset_mini_cubes) - train_size\n",
    "train_dataset, val_dataset = random_split(particle_dataset_mini_cubes, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Define optimizer, loss, and scheduler\n",
    "optimizer = optim.AdamW(segmentation_model.parameters(), lr=1e-5)\n",
    "weights = torch.tensor([0.001] + [1 for _ in range(1, len(particle_types) + 1)]).to(device)  # Lower weight for background\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "# Training loop\n",
    "epochs = 200\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    segmentation_model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = segmentation_model(inputs)\n",
    "        loss = criterion(outputs.view(-1, len(particle_types) + 1), labels.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    segmentation_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = segmentation_model(inputs)\n",
    "            loss = criterion(outputs.view(-1, len(particle_types) + 1), labels.view(-1))\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss / len(train_loader):.8f}, Validation Loss: {val_loss / len(val_loader):.8f}\")\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(segmentation_model.state_dict(), \"segmentation_model_mini_cubes.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_inference(inputs, labels, predictions, sample_idx):\n",
    "    \"\"\"\n",
    "    Visualize the input data, ground truth, and predictions using napari.\n",
    "    \"\"\"\n",
    "    # Create a napari viewer\n",
    "    viewer = napari.Viewer()\n",
    "\n",
    "    # Add input tomogram\n",
    "    viewer.add_image(inputs.cpu().numpy(), name=f\"Sample {sample_idx} - Input\", colormap=\"gray\")\n",
    "\n",
    "    # Add ground truth labels\n",
    "    viewer.add_labels(labels.cpu().numpy(), name=f\"Sample {sample_idx} - Ground Truth\")\n",
    "\n",
    "    # Add predictions\n",
    "    viewer.add_labels(predictions.cpu().numpy(), name=f\"Sample {sample_idx} - Predictions\")\n",
    "\n",
    "    # Start napari viewer\n",
    "    napari.run()\n",
    "\n",
    "# Load the trained model\n",
    "segmentation_model.load_state_dict(torch.load(\"segmentation_model_mini_cubes.pth\"))\n",
    "# Select a few samples from training and validation datasets\n",
    "segmentation_model.eval()\n",
    "for i, (inputs, labels) in enumerate(train_loader):\n",
    "    if i >= 5:  # Visualize only 5 samples\n",
    "        break\n",
    "\n",
    "    inputs, labels = inputs[0].to(device), labels[0].to(device)\n",
    "    # print(inputs.shape, labels.shape)\n",
    "    labels = labels.reshape(16, 16, 16)  # Reshape to (16, 16, 16) for visualization\n",
    "    true_labels = torch.zeros_like(inputs[0]).to(torch.int64) # shape (96, 96, 96)\n",
    "    for z in range(0, 96, 6):\n",
    "        for y in range(0, 96, 6):\n",
    "            for x in range(0, 96, 6):\n",
    "                lz, ly, lx = z//6, y//6, x//6\n",
    "                true_labels[z:z+6, y:y+6, x:x+6] = labels[lz, ly, lx]\n",
    "    # visualize_inference(inputs[0], true_labels, true_labels, sample_idx=i)\n",
    "\n",
    "    inputs = inputs.unsqueeze(1)  # Add channel dimension for model input\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = segmentation_model(inputs)\n",
    "        predictions = torch.argmax(outputs, dim=-1)  # Get predicted class labels\n",
    "        predictions = predictions.reshape(16, 16, 16)  # Reshape to (16, 16, 16) for visualization\n",
    "        true_predictions = torch.zeros_like(inputs[0, 0]).to(torch.int64) # shape (96, 96, 96)\n",
    "        for z in range(0, 96, 6):\n",
    "            for y in range(0, 96, 6):\n",
    "                for x in range(0, 96, 6):\n",
    "                    lz, ly, lx = z//6, y//6, x//6\n",
    "                    true_predictions[z:z+6, y:y+6, x:x+6] = predictions[lz, ly, lx]\n",
    "\n",
    "    # Visualize the first sample in the batch\n",
    "    visualize_inference(inputs[0, 0], true_labels, true_predictions, sample_idx=i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
